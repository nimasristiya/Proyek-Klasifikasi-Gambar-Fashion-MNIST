# -*- coding: utf-8 -*-
"""Submission  Proyek Klasifikasi Gambar

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SYdDnrOQToYL0H-eYXEnv7vzjpS2SwLN

# Proyek Klasifikasi Gambar: Fashion MNIST
- **Nama:** Nimas Ristiya Rahma
- **Email:** nimasristiya@gmail.com
- **ID Dicoding:** nimasristiya

Sumber Dataset
https://www.kaggle.com/datasets/zalando-research/fashionmnist

## Import Semua Packages/Library yang Digunakan
"""

import zipfile
import os
import shutil
import tensorflow as tf
import tensorflowjs as tfjs
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import img_to_array, load_img
from tensorflow.keras.preprocessing import image
from os import getcwd
import pathlib
import numpy as np
import tensorflow_datasets as tfds
from tensorflow.keras import regularizers

# Cetak versi TensorFlow yang sedang digunakan
print(tf.__version__)

"""## Data Preparation

### Data Loading
"""

filePath = f"{getcwd()}/../tmp2/"

(train_examples, validation_examples), info = tfds.load('fashion_mnist',
                                                        data_dir=filePath,
                                                        with_info=True,
                                                        as_supervised=True,
                                                        split=['train[:80%]',
                                                                'train[80%:]'])

num_examples = info.splits['train'].num_examples
num_classes = info.features['label'].num_classes

print(f'Total data: {len(train_examples) + len(validation_examples)}')
print(f'Jumlah data training: {len(train_examples)}')
print(f'Jumlah data validation: {len(validation_examples)}')

class_names = ['T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# Create a labels.txt file with the class names
with open('labels.txt', 'w') as f:
    f.write('\n'.join(class_names))

# The images in the dataset are 28 by 28 pixels.
IMG_SIZE = 28

"""### Data Preprocessing

#### Preprocess Data
"""

def format_example(image, label):
    image = tf.cast(image, dtype=tf.float32)
    image = image/255.0 # Normalize the image in the range [0, 1]

    return image, label

# Specify the batch size
BATCH_SIZE = 256

# Create Datasets
train_batches = train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)
validation_batches = validation_examples.cache().batch(BATCH_SIZE).map(format_example)

"""## Modelling"""

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=16, kernel_size=3, input_shape=(28, 28, 1), activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(units=64, activation='relu'),
    tf.keras.layers.Dense(units=10, activation='softmax')])

model.compile(optimizer='RMSprop',
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])

model.summary()

"""#### Train the model"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy') > 0.9 and epoch >= 10):
      print("\nAkurasi melewati 90%, hentikan proses training!")
      self.model.stop_training = True

callbacks = myCallback()

from tensorflow.keras.callbacks import EarlyStopping

history = model.fit(
    train_batches,
    epochs = 20,
    validation_data = validation_batches,
    verbose =2,
    callbacks=[callbacks]
)

"""## Evaluasi dan Visualisasi"""

# Dapatkan nilai akurasi dan loss dari objek History
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Plot grafik akurasi
plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Training Accuracy')
plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, label='Validation Accuracy')
plt.title('Akurasi Training dan Validation')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
print("")

# Plot grafik loss
plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss')
plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')
plt.title('Loss Training dan Validation')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""## Konversi Model"""

# Simpan model dalam format SavedModel
export_dir = 'saved_model'
tf.saved_model.save(model, export_dir)
print(f"Model SavedModel disimpan di: {export_dir}")

# Simpan model dalam format TensorFlow.js
tfjs_model_dir = 'tfjs_model'
if not os.path.exists(tfjs_model_dir):
    os.makedirs(tfjs_model_dir)
tfjs.converters.save_keras_model(model, tfjs_model_dir)
print(f"Model TFJS disimpan di: {tfjs_model_dir}")

# Konversi dan simpan model dalam format TensorFlow Lite
tflite_model_dir = 'tflite'
if not os.path.exists(tflite_model_dir):
    os.makedirs(tflite_model_dir)

# Select mode of optimization
mode = "Speed"

if mode == 'Storage':
    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE
else:
    optimization = tf.lite.Optimize.DEFAULT

converter.optimizations = [optimization]

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)

# Invoke the converter to finally generate the TFLite model
tflite_model = converter.convert()

# Simpan model TFLite
tflite_model_file = pathlib.Path(f'{tflite_model_dir}/model.tflite')
tflite_model_file.write_bytes(tflite_model)
print(f"Model TFLite disimpan di: {tflite_model_file}")